{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02be0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "plot_parallel_coordinate\n",
    "========================\n",
    "\n",
    ".. autofunction:: optuna.visualization.plot_parallel_coordinate\n",
    "\n",
    "The following code snippet shows how to plot the high-dimensional parameter relationships.\n",
    "\n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "from plotly.io import show\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    x = trial.suggest_float(\"x\", -100, 100)\n",
    "    y = trial.suggest_categorical(\"y\", [-1, 0, 1])\n",
    "    return x**2 + y\n",
    "\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=10)\n",
    "study = optuna.create_study(sampler=sampler)\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "fig = optuna.visualization.plot_parallel_coordinate(study, params=[\"x\", \"y\"])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c366385",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 10:26:40.491204: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-30 10:26:40.517070: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "\u001b[32m2025-06-30 10:26:42.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclassic_rl.rl_corrector\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m368\u001b[0m - \u001b[1mgamma 0.99, clip_epsilon 0.2, gae_lambda 1, lr_actor 0.0003, lr_critic 0.001, k_epochs 80, vf_loss_coef 0.5, action_std 0.2, decay_action_std_rate 0.05, min_action_std 0.01\u001b[0m\n",
      "\u001b[32m2025-06-30 10:26:42.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclassic_rl.rl_corrector\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m369\u001b[0m - \u001b[1mmax_training_timesteps 3000000.0, max_ep_len 1000, update_factor 2 action_std_decay_freq 200000\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : NVIDIA RTX 2000 Ada Generation Laptop GPU\n",
      "============================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-06-30 10:29:06.183\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclassic_rl.rl_corrector\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEpisode : 2 \t Timestep : 2000 \t Average Reward : -4.94\u001b[0m\n",
      "\u001b[32m2025-06-30 10:31:29.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclassic_rl.rl_corrector\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEpisode : 5 \t Timestep : 4000 \t Average Reward : -26.02\u001b[0m\n",
      "\u001b[32m2025-06-30 10:33:52.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclassic_rl.rl_corrector\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEpisode : 7 \t Timestep : 6000 \t Average Reward : -53.74\u001b[0m\n",
      "\u001b[32m2025-06-30 10:36:14.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mclassic_rl.rl_corrector\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m457\u001b[0m - \u001b[1mEpisode : 9 \t Timestep : 8000 \t Average Reward : -70.87\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      3\u001b[39m env = gym.make(\u001b[33m\"\u001b[39m\u001b[33mMountainCarContinuous-v0\u001b[39m\u001b[33m\"\u001b[39m) \n\u001b[32m      5\u001b[39m corrector = PPOCorrector(env, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, hidden_size=\u001b[32m64\u001b[39m, lr_actor=\u001b[32m3e-4\u001b[39m, lr_critic=\u001b[32m1e-3\u001b[39m, gamma=\u001b[32m0.99\u001b[39m, k_epochs=\u001b[32m80\u001b[39m, clip_epsilon=\u001b[32m0.2\u001b[39m, gae_lambda=\u001b[32m1\u001b[39m, action_std_init = \u001b[32m0.2\u001b[39m, decay_action_std = \u001b[32m0.05\u001b[39m, min_action_std = \u001b[32m0.01\u001b[39m, max_training_timesteps = \u001b[32m3e6\u001b[39m, max_ep_len = \u001b[32m1000\u001b[39m, update_factor = \u001b[32m2\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m log = \u001b[43mcorrector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SmartDartCorrector/classic_rl/rl_corrector.py:432\u001b[39m, in \u001b[36mPPOCorrector.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    430\u001b[39m \u001b[38;5;66;03m# update PPO agent\u001b[39;00m\n\u001b[32m    431\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_step % \u001b[38;5;28mself\u001b[39m.update_timestep == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m432\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mppo_agent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# if continuous action space; then decay action std of ouput action distribution\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m time_step % \u001b[38;5;28mself\u001b[39m.action_std_decay_freq == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/SmartDartCorrector/classic_rl/PPO.py:244\u001b[39m, in \u001b[36mPPO.update\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m# take gradient step\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimizer.step()\n\u001b[32m    247\u001b[39m \u001b[38;5;66;03m# Copy new weights into old policy\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/env_aiming/lib/python3.11/site-packages/torch/_tensor.py:648\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    639\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    640\u001b[39m         Tensor.backward,\n\u001b[32m    641\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    646\u001b[39m         inputs=inputs,\n\u001b[32m    647\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m648\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/env_aiming/lib/python3.11/site-packages/torch/autograd/__init__.py:353\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    348\u001b[39m     retain_graph = create_graph\n\u001b[32m    350\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m353\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/env_aiming/lib/python3.11/site-packages/torch/autograd/graph.py:824\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    822\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    823\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    825\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    828\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "from classic_rl.rl_corrector import *\n",
    "env = gym.make(\"MountainCarContinuous-v0\") \n",
    "\n",
    "corrector = PPOCorrector(env, None, None, hidden_size=64, lr_actor=3e-4, lr_critic=1e-3, gamma=0.99, k_epochs=80, clip_epsilon=0.2, gae_lambda=1, action_std_init = 0.2, decay_action_std = 0.05, min_action_std = 0.01, max_training_timesteps = 3e6, max_ep_len = 1000, update_factor = 2)\n",
    "\n",
    "\n",
    "log = corrector.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_aiming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
